\section*{Appendix}
\label{s:appendix}

\section{Zero-Shot Prompt}
\label{sec:zeroshot-prompt}

The Zero-Shot Prompt in Figure~\ref{fig:naive_zeroshot} provides a brief context for the SLM to understand that the focus language is KQL, and asks the SLM to produce a 
KQL query based on a NLQ. No additional context is given in this prompt, as this is meant to assess the SLM's understanding of KQL at a baseline level. This prompt is related to 
the results outlined from RQ1.

\begin{figure}[!t]
    \centering
    \begin{tcolorbox}[enhanced,
        attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},
        colback=blue!5!white,
        colframe=blue!75!black,
        colbacktitle=blue!80!black,
        title=Zero-Shot Prompting,
        fonttitle=\bfseries,
        boxed title style={size=small,colframe=red!50!black}, ,
      left=2mm, right=2mm, top=2mm, bottom=1mm, boxsep=1pt
    ]
    \footnotesize
    You are a programmer using the Kusto Query Language with Microsoft Defender.
    Generate a KQL query that answers the following request:
    \newline\newline
    \{NLQ\}
    \newline\newline
    Return only the KQL code without any explanation.
    \end{tcolorbox}
    \caption{Zero-Shot prompt used to evaluate how SLMs generate KQL queries}
    \label{fig:naive_zeroshot}
\end{figure}

\section{Alternative Prompts}
\label{sec:prompt-specs}
% \wajih{Like I did for other prompts in the main paper, convert this into latex figure and refer to it in the paragraph. Also refer to which subsection/section it relates to from the main paper.}
We introduce two revised prompt templates targeting common errors we found using Microsoft's KQL Parser; see Figure ~\ref{fig:alternative-prompting}.  Alternative Prompt 1 tackles the most frequent syntax error (improper timestamp ranges) by showing the model correct examples of how to use the "between" operator. Alternative Prompt 2 builds on this by adding rules to help the model check that columns actually belong to the tables they reference and avoid using undefined identifiers. Both prompts keep the same NL2KQL structure but add helpful tips to improve accuracy without bloating the token count.
This complements the NL2KQL setup described in Section~\ref{sec:nl2kql-config}.


\begin{figure}[!t]
    \centering
    \begin{tcolorbox}[enhanced,attach boxed title to top center={yshift=-3mm,yshifttext=-1mm},
        colback=blue!5!white,colframe=blue!75!black,colbacktitle=blue!80!black,
        title=Alternative Prompting Methods,fonttitle=\bfseries,
        boxed title style={size=small,colframe=red!50!black}]
        \scriptsize
        \textbf{Alternative Prompt \#1:}
    
        You are a programmer using the Kusto Query Language with Microsoft Defender. Focus on producing syntactically correct KQL queries, you may use the following tip to help as well:
        \newline
        \newline
        1. Use the following structures to describe a timestamp: between(datetime(``2025-01-01T12:00:00Z") .. datetime(``2025-01-01T12:01:00Z")), Timestamp $<$ ago(7d)
        \newline
        \newline
        Utilize the following tables, columns, and data types:
        \newline
        \newline
        \{SCHEMA\}
        \newline
        \newline
        Return only the KQL code without any explanation. Here are some examples:
        \newline
        \newline
        \{EXAMPLES\}
        \newline
        \newline
        \{NLQ\}
        \newline
        \rule{\linewidth}{0.4pt}
        \textbf{Alternative Prompt \#2:}
    
        You are a programmer using the Kusto Query Language with Microsoft Defender. Focus on producing syntactically and semantically correct KQL queries, you may use the following tips to help as well:
        \newline
        \newline
        1. Use the following structures to describe a timestamp: between(datetime(``2025-01-01T12:00:00Z" .. datetime(``2025-01-01T12:01:00Z")), Timestamp $<$ ago(7d)
        \newline
        2. When generating a KQL query, ensure that ALL columns mentioned in the result belong to the correct table mentioned.
        \newline
        Utilize the following tables, columns, and data types:
        \newline
        \newline
        \{SCHEMA\}
        \newline
        \newline
        Return only the KQL code without any explanation. Here are some examples:
        \newline
        \newline
        \{EXAMPLES\}
        \newline
        \newline
        \{NLQ\}
        \label{box:rq3-box2}
    \end{tcolorbox}
    \caption{Alternative prompting templates used to reduce common KQL errors.}
    \label{fig:alternative-prompting}
\end{figure}

\section{Table References}
Table~\ref{tab:syntax_tbl} outputs the most common syntax errors that were associated in the Gemma-3-4B-IT NL2KQL Configuration (RQ2). In total, there were 
685 syntax errors from the LLM-generated KQL queries across five iterations. Although the overwhelming majority of errors involve an expected semicolon, this is not particularly 
useful in fixing the KQL queries. However, the last error, "Expected .." highlights an error when constructing timestamp ranges. This information is used to formulate the first prompting 
strategy in RQ3.
% \wajih{Rahul, you need to refer to the tables in this subsection. Explain what each table represents and which part of evaluation it relates to. Make sure to use latex references.}

\begin{table}[!t]
    \centering
    \scriptsize
    \begin{tabular}{c c}
        \toprule
        \textbf{Syntax Error} & \textbf{Percentage of Errors} \\
        \midrule
        Expected: ; & 23.9\% \\
        \midrule
        The incomplete fragment is unexpected. & 14.4\% \\
        \midrule
        Expected ) & 13.1\% \\
        \midrule
        Expected .. & 10.8\%\\
        \bottomrule
    \end{tabular}
    \caption{List of most common syntax errors associated with the Gemma-3-4B-IT NL2KQL Configuration over five iterations (Total Syntax Error Count: 685)}.
    \label{tab:syntax_tbl}
\end{table}

Table~\ref{tab:syntax_tbl_additional} shows the most common syntax errors that were found after the changes in prompting in the Gemma-3-4B-IT NL2KQL Configuration. Not only has the number 
of syntax errors reduced with the new prompting strategy, but previously common errors such as "Expected .." no longer appear within the top errors found.

\begin{table}[!t]
    \centering
        \scriptsize
    \begin{tabular}{cc}
        \toprule
        \textbf{Syntax Error} & \textbf{Percentage of Errors} \\
        \midrule
        Expected: ; & 28.3\% \\
        \midrule
        Unexpected \\ & 28.1\% \\
        \midrule
        The incomplete fragment is unexpected. & 19.4\% \\
        \midrule
        Expected , & 6.5\% \\
        \bottomrule
    \end{tabular}
    \caption{List of most common syntax errors associated with the revised prompting strategy. (Total Syntax Error Count over five iterations: 459)}
    \label{tab:syntax_tbl_additional}
\end{table}

Table~\ref{tab:semantic-tbl} outlines the most common semantic errors that were found after the changes in prompting in the Gemma-3-4B-IT NL2KQL Configuration. Although only the top 5 common semantic 
errors are highlighted here, the majority of semantic errors detected involve column names that did not belong to the correct tables. This is possible due to SLM hallucinations or misguided 
assumptions from SLMs that a particular column belongs to a certain table.

\begin{table}[!t]
    \centering
        \scriptsize
    \begin{tabular}{p{4cm}c}
        \toprule
        \textbf{Semantic Error} & \textbf{Percentage of Errors} \\
        \midrule
        Expected: ; & 9.2\% \\
        \midrule
        Unexpected \\ & 9.2\% \\
        \midrule
        The incomplete fragment is unexpected & 6.3\% \\
        \midrule
        The name 'CommandLine' does not refer to any known column, table, variable or function. & 2.6\% \\
        \bottomrule
    \end{tabular}
    \caption{List of most common semantic errors associated with the first revised prompting strategy. (Total Semantic Error Count over five iterations: 1408)}
    \label{tab:semantic-tbl}
\end{table}

Table~\ref{tab:semantic-tbl-additional} outlines the most common semantic errors that were found after a second change prompting in the Gemma-3-4B-IT NL2KQL Configuration. With the 
second revised prompting technique, the number of semantic errors increase. This shows that the second revised prompting strategy did not assist in reducing the 
number of semantic errors detected.

\begin{table}[!t]
    \centering
                \scriptsize
    \begin{tabular}{p{4cm}c}

        \toprule
        \textbf{Semantic Error} & \textbf{Percentage of Errors} \\
        \midrule
        Unexpected: \\ & 17.0\% \\
        \midrule
        The incomplete fragment is unexpected. & 8.9\% \\
        \midrule
        Expected ; & 7.6\% \\
        \midrule
        The name 'Timestamp' does not refer to any known column, table, variable or function. & 2.0\% \\
        \bottomrule
    \end{tabular}
    \caption{List of most common semantic errors associated with the second revised prompting strategy. (Total Semantic Error Count over five iterations: 1714)}
    \label{tab:semantic-tbl-additional}
\end{table}


\subsection{RQ6: Generalization}
\label{sec:general}
% \Fix{Don't use the word Multi-Agent.}

After establishing a two-staged architecture, we seek to understand how this two-staged architecture performs on different table and schema sets. In order
to test how this system performs on other schemas, we utilize the NL2KQL Sentinel-Queries Dataset \cite{reprise99} for evaluation. We use the same prompting strategy
utilized in the Two-Staged Architecture Solution w/Schema Context, and continue to set the temperature to 1 for the SLM in the two-staged architecture system.


When given a new dataset, the two-staged architecture performs well in developing syntactically and semantically correct KQL queries without incurring higher latency and
token costs. However, the two-staged architecture does not perform as well in recognizing the correct tables needed to develop the proper KQL query, and performs poorly
in identifying the correct columns that should be utilized in the KQL queries. This shows that although the two-staged architecture shows strong promise in producing
syntactically and semantically correct KQL queries, it may also produce misleading KQL queries as the tables and columns utilized may be incorrectly used in the result.


\begin{table}[!h]
\centering
\footnotesize
\setlength{\tabcolsep}{2pt} % tighten horizontal padding
\begin{tabular}{p{2.3cm}ccccccc}
\hline
\textbf{Configuration (w/NL2KQL)} & \textbf{Syntax} & \textbf{Semantic} & \textbf{Table} & \textbf{Filter$_{\text{col}}$} & \textbf{Filter$_{\text{lit}}$} & \textbf{Lat.} & \textbf{AC.} \\
\hline
Two-Staged Architecture Solution (Schema Context) & 0.971 & 0.769 & 0.414 & 0.224 & 0.118 & 3.031 & \$0.015 \\
\hline
\end{tabular}
\caption{Evaluation of NL2KQL and multiple SLM configurations on the Sentinel-Queries Dataset. Lat. stands for Latency; AC. stands for Average Cost}
\label{tab:nl2kql-final-sentinel-eval}
\end{table}


\begin{figure}[!t]
  \centering
  \includegraphics[width=0.80\columnwidth]{fig/ablation_one.png}
  \caption{Number of SLMs (1-4) vs. Metric Scores}
  \label{fig:ablation_one}
  \vspace{-2ex}
\end{figure}

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.80\columnwidth]{fig/ablation_two.png}
  \caption{Temperature vs. Metric Scores}
  \label{fig:ablation_two}
  \vspace{-2ex}
\end{figure}


\section{RQ7: Ablation Studies}
\label{sec:ablation}

% \wajih{You change NL2KQL’s “top 9” to “top 5” tables and drop column values to save tokens, but give no principled basis (e.g., cost-quality curve)}

% \wajih{You inherit a cosine-similarity threshold (0.9) for embedding-based replacement without reporting sensitivity or confirming it still holds under your substitutions. This is an ablation study.}
% Making a note - will work on this after paper submission.

In the following section, we vary different components of the two-staged architecture and assess how this affects the overall results of the system. The three main areas of testing include the \textbf{number of SLMs}
that are used within the two-staged architecture system, the different \textbf{temperature values} used within the two-staged architecture system, and the \textbf{number of tables} fed into the SLM and Oracle LLM prompt.

\begin{table*}[!t]
  \centering
  \footnotesize
  \begin{tabular}{ll*{7}{w{c}{0.06\textwidth}}}
    \toprule
  \textbf{Category} & \textbf{Model Configuration} & \textbf{Syntax} & \textbf{Semantic} & \textbf{Table} & \textbf{Filter$_{\text{col}}$} & \textbf{Filter$_{\text{lit}}$} & \textbf{Latency} & \textbf{Avg. Cost}\\
  \multirow{5}{*}{\makecell[l]{Multi-Agent\\(Top t tables)}}
  & Multi-Agent (Top 1) & 0.963 & 0.803 & 0.571 & 0.532 & 0.552 & 2.229 & \$0.018 \\
  & Multi-Agent (Top 3) & 0.969 & 0.849 & 0.620 & 0.515 & 0.567 & 2.691 & \$0.030 \\
  & Multi-Agent (Top 5) & 0.969 & 0.870 & 0.639 & 0.500 & 0.565 & 2.803 & \$0.040 \\
  & Multi-Agent (Top 7) & 0.965 & 0.860 & 0.704 & 0.501 & 0.567 & 2.816 & \$0.050 \\
  & Multi-Agent (Top 9) & 0.977 & 0.867 & 0.754 & 0.500 & 0.569 & 2.812 & \$0.059 \\
  \bottomrule
  \end{tabular}
  \caption{Evaluation of Multi-Agent System with varying numbers of tables.}
  \label{tab:appendix-ablation-tables}
  \end{table*}

\PP{Number of SLMs}
The number of SLMs that are utilized in the two-staged architecture solution can potentially introduce a tradeoff between metric scores and latency. A greater number of SLMs utilized in the system often means that the system will likely incur higher latency.
However, the greater the number of SLMs that are utilized in the two-staged architecture solution, the more plausible responses are generated. In this ablation study, we determine what effect the number of SLMs utilized has on responses while keeping other
components (i.e. Temperature) consistent. Figure~\ref{fig:ablation_one} outlines the metric scores as the number of SLMs utilized in the system increases. Increasing the number of SLMs utilized in the system reduces all metric scores in the entire two-staged system. When the number of SLMs utilized in the two-staged system is one, the syntax score is 0.969, the semantic score is
0.870, the table score is 0.639, the $Filter_{col}$ score is 0.500, and the $Filter_{lit}$ score is 0.565. However, when the number of SLMs utilized in the two-staged system increases to two, the syntax score is reduced to 0.954,
the semantic score is reduced to 0.815, the table score is reduced to 0.623, the $Filter_{col}$ score is reduced to 0.495, and the $Filter_{lit}$ score is reduced to 0.557. This reduction trend continues as the number of SLMs utilized
in the system continue to increase as shown by the figure. Therefore, the best number of SLMs to utilize in the multi-stage system is one.





\PP{Different Temperature Values}
We tested the two-staged architecture system under four different temperature values: 0.2, 0.7, 1.2, 1.7. These temperature values are meant to represent low, moderate, and high temperature values respectively. When configured within SLMs, low temperatures provide more deterministic
code while higher temperatures introduce more randomness and creativity in token generation. In this ablation study, we study how varying the temperature of the SLMs can affect the quality of KQL queries that are produced from the proposed system. Figure~\ref{fig:ablation_two} outlines the metric scores as the temperature utilized in the SLM within the two-staged system varies. When the temperature
is set to 0.2, the syntax score is 0.969, the semantic score is 0.864, the table score is 0.641, the $Filter_{col}$ score is 0.501, and the $Filter_{lit}$ score is 0.573. When the temperature is set to 0.7, the syntax score is reduced to 0.966, the semantic score is reduced to 0.862, the table score is increased to 0.646, the $Filter_{col}$ score is increased slightly to 0.510, and the $Filter_{lit}$ score is reduced to 0.571.
When the temperature is set to 1.2, the syntax score is 0.964, the semantic score is 0.850, the table score is 0.626,  the $Filter_{col}$ score is 0.507, and the $Filter_{lit}$ score is 0.566. Lastly, when the temperature is set to 1.7, the syntax score is 0.971, the semantic score is 0.850, the table score is 0.647, the $Filter_{col}$ score is 0.520, and the $Filter_{lit}$ score is 0.567. There does not appear to be a clear
relationship between temperature and performance, however the semantic score does decrease as the temperature increases. However, in the previous ablation study when the number of SLMs utilized is 1 and the temperature is set to 1, the reported semantic score is 0.870.

\PP{Different Number of Tables} We tested the two-staged architecture when it receives the top five tables and when it receives the top nine tables, as originally proposed in NL2KQL. The goal in providing the top five tables instead of the top nine tables is to reduce total costs in utilizing the system.
However, we also seek to determine how reducing the number of tables given to the SLM and Oracle LLM affects other metrics. These results are shown in Table~\ref{tab:appendix-ablation-tables}.

While the syntax scores remain stable across varying levels of tables supplied, the semantic score increases as the number of tables supplied to the pipeline increase. Furthermore, the table scores increase as well and as does the costs need to run the queries. To reach a good balance between 
cost, efficiency, and metrics, we choose our ideal number of tables to supply to the system as five.

\PP{Different Alpha and Rank Values}

In Table~\ref{tab:alpharank} and Table~\ref{tab:alpharank_two}, we highlight the validation losses obtained from each combination of parameters while training the Gemma-3-4B-IT SLM on NLQ-KQL pairs. 
Table~\ref{tab:alpharank} highlights the validation loss in the Supervised Fine-Tuning case, while Table~\ref{tab:alpharank_two} highlights the validation loss in the COT Fine-Tuning case. 

\begin{table}[!t]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Alpha} & \textbf{Rank} & \textbf{LoRA Dropout} & \textbf{Validation Loss} \\
        \hline
        2 & 1 & 0.1 & 0.789 \\
        \hline
        2 & 1 & 0.2 & 0.778 \\
        \hline
        2 & 2 & 0.1 & 0.784 \\
        \hline
        2 & 2 & 0.2 & 0.783 \\
        \hline
        2 & 4 & 0.1 & 0.764 \\
        \hline
        2 & 4 & 0.2 & 0.765 \\
        \hline
        4 & 1 & 0.1 & 0.724 \\
        \hline
        4 & 1 & 0.2 & 0.726 \\
        \hline
        4 & 2 & 0.1 & 0.722 \\
        \hline
        4 & 2 & 0.2 & 0.723 \\
        \hline
        4 & 4 & 0.1 & 0.704 \\
        \hline
        4 & 4 & 0.2 & 0.708 \\
        \hline
        8 & 1 & 0.1 & 0.681 \\
        \hline
        8 & 1 & 0.2 & 0.686 \\
        \hline
        8 & 2 & 0.1 & 0.676 \\
        \hline
        8 & 2 & 0.2 & 0.678 \\
        \hline
        8 & 4 & 0.1 & 0.669 \\
        \hline
        8 & 4 & 0.2 & 0.667 \\
        \hline
    \end{tabular}
    \caption{Hyperparameter Search with Validation Losses per combination (Supervised Fine-Tuning)}
    \label{tab:alpharank}
\end{table}

\begin{table}[!t]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Alpha} & \textbf{Rank} & \textbf{LoRA Dropout} & \textbf{Validation Loss} \\
        \hline
        2 & 1 & 0.1 & 0.722 \\
        \midrule
        2 & 1 & 0.2 & 0.721 \\
        \midrule
        2 & 2 & 0.1 & 0.73 \\
        \midrule
        2 & 2 & 0.2 & 0.731 \\
        \midrule
        2 & 4 & 0.1 & 0.732 \\
        \midrule
        2 & 4 & 0.2 & 0.733 \\
        \midrule
        4 & 1 & 0.1 & 0.697 \\
        \midrule
        4 & 1 & 0.2 & 0.697 \\
        \midrule
        4 & 2 & 0.1 & 0.691 \\
        \midrule
        4 & 2 & 0.2 & 0.692 \\
        \midrule
        4 & 4 & 0.1 & 0.691 \\
        \midrule
        4 & 4 & 0.2 & 0.692 \\
        \midrule
        8 & 1 & 0.1 & 0.677 \\
        \midrule
        8 & 1 & 0.2 & 0.678 \\
        \midrule
        8 & 2 & 0.1 & 0.671 \\
        \midrule
        8 & 2 & 0.2 & 0.672 \\
        \midrule
        8 & 4 & 0.1 & 0.668 \\
        \midrule
        8 & 4 & 0.2 & 0.668 \\
        \midrule
        \hline
    \end{tabular}
    \caption{Hyperparameter Search with Validation Losses per combination (CoT Fine-Tuning)}
    \label{tab:alpharank_two}
\end{table}


% 2 & 1 & 0.1 & 0.722 \\
% \midrule
% 2 & 1 & 0.2 & 0.721 \\
% \midrule
% 2 & 2 & 0.1 & 0.73 \\
% \midrule
% 2 & 2 & 0.2 & 0.731 \\
% \midrule
% 2 & 4 & 0.1 & 0.732 \\
% \midrule
% 2 & 4 & 0.2 & 0.733 \\
% \midrule
% 4 & 1 & 0.1 & 0.697 \\
% \midrule
% 4 & 1 & 0.2 & 0.697 \\
% \midrule
% 4 & 2 & 0.1 & 0.691 \\
% \midrule
% 4 & 2 & 0.2 & 0.692 \\
% \midrule
% 4 & 4 & 0.1 & 0.691 \\
% \midrule
% 4 & 4 & 0.2 & 0.692 \\
% \midrule
% 8 & 1 & 0.1 & 0.677 \\
% \midrule
% 8 & 1 & 0.2 & 0.678 \\
% \midrule
% 8 & 2 & 0.1 & 0.671 \\
% \midrule
% 8 & 2 & 0.2 & 0.672 \\
% \midrule
% 8 & 4 & 0.1 & 0.668 \\
% \midrule
% 8 & 4 & 0.2 & 0.668 \\
% \midrule
