\begin{table*}[!t]
  \centering
  \footnotesize
  \begin{tabular}{ll*{7}{w{c}{0.06\textwidth}}}
    \toprule
  \textbf{Category} & \textbf{Model Configuration} & \textbf{Syntax} & \textbf{Semantic} & \textbf{Table} & \textbf{Filter$_{\text{col}}$} & \textbf{Filter$_{\text{lit}}$} & \textbf{Latency} & \textbf{Avg. Cost}\\
  \midrule
  Baseline & NL2KQL & 0.988 & 0.960 & 0.822 & 0.699 & 0.666 & -- & -- \\
  \midrule
  \multirow{3}{*}{\makecell[l]{Prompting\\Strategies}}
  & NL2KQL + Gemma-3-4B-IT (Original) & 0.819 & 0.408 & 0.634 & 0.306 & 0.493 & 6.851 & \$0.036 \\
  & NL2KQL + Gemma-3-4B-IT (Revised \#1) & 0.863 & 0.588 & 0.656 & 0.403 & 0.489 & 2.172 & \$0.018 \\
  & NL2KQL + Gemma-3-4B-IT (Revised \#2) & 0.809 & 0.550 & 0.648 & 0.381 & 0.479 & 2.178 & \$0.018 \\
  \midrule
  \multirow{4}{*}{\makecell[l]{Advanced\\Configurations}}
  % & Gemini 2.0 Flash & 0.922 & 0.787 & 0.678 & 0.478 & 0.517 & 11.109 & \$0.540 \\
  & Gemma-3-4B-IT (Supervised LoRA Fine-Tuning) & 0.545 & 0.298 & 0.567 & 0.274 & 0.441 & 3.369 & \$0.018 \\
  & Gemma-3-4B-IT (CoT LoRA Fine-Tuning) & 0.852 & 0.465 & 0.557 & 0.298 & 0.385 & 3.347 & \$0.018 \\
  & Multi-Agent (General Refinement) & 0.978 & 0.503 & 0.566 & 0.377 & 0.560 & 2.689 & \$0.022 \\
  & Multi-Agent (Schema Context) & 0.969 & 0.870 & 0.639 & 0.500 & 0.565 & 2.803 & \$0.040 \\
  \bottomrule
  \end{tabular}
  \caption{Evaluation of NL2KQL and various model configurations on the Defender Dataset.}
  \label{tab:nl2kql-eval}
  \end{table*}

  % \wajih{Make table header bold and make sure that Table 3 and Table 2 header use same font. For example Filter-col looks different in these two tables.

  % \begin{table*}[!t]
  % \centering
  % \footnotesize
  % \begin{tabular}{ll*{7}{w{c}{0.06\textwidth}}}
  %   \toprule
  % \textbf{Category} & \textbf{Model Configuration} & \textbf{Syntax} & \textbf{Semantic} & \textbf{Table} & \textbf{Filter$_{\text{col}}$} & \textbf{Filter$_{\text{lit}}$} & \textbf{Latency} & \textbf{Avg. Cost}\\
  % \multirow{5}{*}{\makecell[l]{Prompting\\Strategies}}
  % & Multi-Agent (Top 1) & 0.969 & 0.870 & 0.639 & 0.500 & 0.565 & 2.803 & \$0.034 \\
  % & Multi-Agent (Top 3) & 0.977 & 0.867 & 0.754 & 0.500 & 0.570 & 2.812 & \$0.050 \\
  % & Multi-Agent (Top 5) & 0.969 & 0.870 & 0.639 & 0.500 & 0.565 & 2.803 & \$0.034 \\
  % & Multi-Agent (Top 7) & 0.977 & 0.867 & 0.754 & 0.500 & 0.570 & 2.812 & \$0.050 \\
  % & Multi-Agent (Top 9) & 0.977 & 0.867 & 0.754 & 0.500 & 0.570 & 2.812 & \$0.050 \\
  
  % % & NL2KQL + Gemma-3-4B-IT (Original) & 0.803 & 0.400 & 0.634 & 0.306 & 0.492 & 6.851 & \$0.018 \\
  % % & NL2KQL + Gemma-3-4B-IT (Revised \#1) & 0.863 & 0.588 & 0.656 & 0.403 & 0.489 & 2.172 & \$0.009 \\
  % % & NL2KQL + Gemma-3-4B-IT (Revised \#2) & 0.807 & 0.550 & 0.647 & 0.381 & 0.479 & 2.178 & \$0.009 \\
  % \bottomrule
  % \end{tabular}
  % \caption{Evaluation of NL2KQL and various model configurations on the Defender Dataset.}
  % \label{tab:appendix-ablation-tables}
  % \end{table*}
  % % & Multi-Agent (Top 5) & 0.969 & 0.870 & 0.639 & 0.500 & 0.565 & 2.803 & \$0.034 \\
  % % & Multi-Agent (Top 9) & 0.977 & 0.867 & 0.754 & 0.500 & 0.570 & 2.812 & \$0.050 \\